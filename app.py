import streamlit as st
import pandas as pd
import random
import base64
from pathlib import Path
import re
from io import BytesIO

# =========================
# CONFIG
# =========================
st.set_page_config(page_title="Sora Prompt Studio Pro ‚Äì Director Edition", layout="wide")
st.title("üé¨ Sora Prompt Studio Pro ‚Äì Director Edition")
st.caption("Prompt 1 & 2 ‚Ä¢ Timeline tho·∫°i chu·∫©n ‚Ä¢ Kh√¥ng tr√πng ‚Ä¢ TikTok Shop SAFE")

CAMEO_VOICE_ID = "@phuongnghi18091991"
SHOE_TYPES = ["sneaker", "runner", "leather", "casual", "sandals", "boots", "luxury"]

# =========================
# COPY BUTTON (1 CLICK)
# =========================
def copy_button(text: str, key: str):
    b64 = base64.b64encode(text.encode("utf-8")).decode("utf-8")
    html = f"""
    <button id="{key}" style="
        padding:8px 14px;border-radius:10px;border:1px solid #ccc;
        cursor:pointer;background:#fff;font-weight:600;">üìã COPY</button>
    <span id="{key}_s" style="margin-left:8px;font-size:12px;"></span>
    <script>
    const btn = document.getElementById("{key}");
    const s = document.getElementById("{key}_s");
    btn.onclick = async () => {{
        try {{
            await navigator.clipboard.writeText(atob("{b64}"));
            s.innerText = "‚úÖ ƒê√£ copy";
            setTimeout(()=>s.innerText="",1500);
        }} catch(e) {{
            s.innerText = "‚ö†Ô∏è Kh√¥ng copy ƒë∆∞·ª£c";
            setTimeout(()=>s.innerText="",2500);
        }}
    }}
    </script>
    """
    st.components.v1.html(html, height=42)

# =========================
# FILE CHECK
# =========================
required_files = ["dialogue_library.csv", "scene_library.csv", "disclaimer_prompt2.csv"]
missing = [f for f in required_files if not Path(f).exists()]
if missing:
    st.error(f"‚ùå Thi·∫øu file: {', '.join(missing)} (ph·∫£i n·∫±m c√πng th∆∞ m·ª•c app.py)")
    st.stop()

# =========================
# LOAD CSV
# =========================
@st.cache_data
def load_dialogues():
    df = pd.read_csv("dialogue_library.csv")
    return df.to_dict(orient="records"), df.columns.tolist()

@st.cache_data
def load_scenes():
    df = pd.read_csv("scene_library.csv")
    return df.to_dict(orient="records"), df.columns.tolist()

@st.cache_data
def load_disclaimer_prompt2_flexible():
    """
    H·ªó tr·ª£ m·ªçi ki·ªÉu header cho disclaimer_prompt2.csv
    - ∆∞u ti√™n c·ªôt 'disclaimer'
    - n·∫øu kh√¥ng c√≥ -> th·ª≠ text/content/note...
    - n·∫øu v·∫´n kh√¥ng -> n·∫øu c·ªôt 1 l√† id -> l·∫•y c·ªôt 2, else l·∫•y c·ªôt cu·ªëi
    """
    df = pd.read_csv("disclaimer_prompt2.csv")
    cols = [c.strip() for c in df.columns.tolist()]

    if "disclaimer" in cols:
        arr = df["disclaimer"].dropna().astype(str).tolist()
        return [x.strip() for x in arr if x.strip()]

    preferred = ["text", "mien_tru", "mi·ªÖn_tr·ª´", "note", "content", "noi_dung", "line"]
    for c in preferred:
        if c in cols:
            arr = df[c].dropna().astype(str).tolist()
            return [x.strip() for x in arr if x.strip()]

    if len(cols) >= 2 and cols[0].lower() in ["id", "stt", "no"]:
        arr = df[cols[1]].dropna().astype(str).tolist()
        return [x.strip() for x in arr if x.strip()]

    last = cols[-1]
    arr = df[last].dropna().astype(str).tolist()
    return [x.strip() for x in arr if x.strip()]

@st.cache_data
def load_disclaimer_prompt1_optional():
    p = Path("disclaimer_prompt1.csv")
    if not p.exists():
        return None
    df = pd.read_csv(str(p))
    cols = [c.strip() for c in df.columns.tolist()]
    if "disclaimer" in cols:
        arr = df["disclaimer"].dropna().astype(str).tolist()
        arr = [x.strip() for x in arr if x.strip()]
        return arr if arr else None
    last = cols[-1]
    arr = df[last].dropna().astype(str).tolist()
    arr = [x.strip() for x in arr if x.strip()]
    return arr if arr else None

dialogues, dialogue_cols = load_dialogues()
scenes, scene_cols = load_scenes()
disclaimers_p2 = load_disclaimer_prompt2_flexible()
disclaimers_p1 = load_disclaimer_prompt1_optional()

DISCLAIMER_P1_FALLBACK = [
    "N·ªôi dung ch·ªâ mang t√≠nh chia s·∫ª tr·∫£i nghi·ªám c√° nh√¢n.",
    "Video mang t√≠nh minh h·ªça tr·∫£i nghi·ªám, kh√¥ng k√™u g·ªçi h√†nh ƒë·ªông.",
    "Tr·∫£i nghi·ªám c√≥ th·ªÉ kh√°c nhau t√πy t·ª´ng ng∆∞·ªùi v√† ƒëi·ªÅu ki·ªán s·ª≠ d·ª•ng.",
    "Th√¥ng tin trong video mang t√≠nh tham kh·∫£o.",
    "Chi ti·∫øt c·ª• th·ªÉ vui l√≤ng xem theo t·ª´ng s·∫£n ph·∫©m.",
    "N·ªôi dung kh√¥ng ƒë·ªÅ c·∫≠p mua b√°n, gi√° hay khuy·∫øn m√£i.",
    "Video ghi l·∫°i kho·∫£nh kh·∫Øc s·ª≠ d·ª•ng th·ª±c t·∫ø, kh√¥ng cam k·∫øt tuy·ªát ƒë·ªëi.",
    "M·ªói m·∫´u c√≥ th√¥ng tin ri√™ng, vui l√≤ng tham kh·∫£o trang s·∫£n ph·∫©m.",
    "N·ªôi dung kh√¥ng so s√°nh v·ªõi s·∫£n ph·∫©m kh√°c.",
    "Video t·∫≠p trung tr·∫£i nghi·ªám h√¨nh ·∫£nh v√† chuy·ªÉn ƒë·ªông."
]

# =========================
# MEMORY ‚Äì CH·ªêNG TR√ôNG + PROMPTS
# =========================
if "used_dialogue_ids" not in st.session_state:
    st.session_state.used_dialogue_ids = set()
if "used_scene_ids" not in st.session_state:
    st.session_state.used_scene_ids = set()
if "generated_prompts" not in st.session_state:
    st.session_state.generated_prompts = []
if "used_voice_lines" not in st.session_state:
    st.session_state.used_voice_lines = set()

def pick_unique(pool, used_ids: set, key: str):
    items = [x for x in pool if str(x.get(key, "")).strip() not in used_ids]
    if not items:
        used_ids.clear()
        items = pool[:]
    item = random.choice(items)
    used_ids.add(str(item.get(key, "")).strip())
    return item

# =========================
# UTILS
# =========================
def safe_text(v):
    if v is None:
        return ""
    try:
        if pd.isna(v):
            return ""
    except Exception:
        pass
    s = str(v).strip()
    if s.lower() == "nan":
        return ""
    return s

def normalize_filename(name: str) -> str:
    n = (name or "").lower()
    n = re.sub(r"\.(jpg|jpeg|png|webp|bmp)$", "", n)
    n = re.sub(r"[^a-z0-9_ -]", " ", n)
    n = re.sub(r"\s+", " ", n).strip()
    return n

def extract_shoe_name(name: str) -> str:
    # L·∫•y t√™n "ƒë·∫πp" t·ª´ filename: b·ªè ƒëu√¥i, b·ªè timestamp d√†i, b·ªè c·ª•m v√¥ nghƒ©a
    n = normalize_filename(name)
    # b·ªè chu·ªói s·ªë d√†i (timestamp)
    n = re.sub(r"\b\d{8,}\b", "", n).strip()
    # r√∫t g·ªçn
    if not n:
        return "uploaded_shoe"
    # gi·ªõi h·∫°n ƒë·ªô d√†i
    return n[:60]

# =========================
# SMART AUTO DETECT shoe_type (FIXED)
# =========================
KEYWORD_RULES = {
    "leather": [
        "loafer", "loafers", "horsebit", "bit", "oxford", "derby", "monk", "monkstrap",
        "brogue", "formal", "dress", "moc", "moccasin", "mocassin", "giay-da", "giay da",
        "da-nam", "da nam", "cong so", "cong-so", "tay", "slipon", "slip-on"
    ],
    "luxury": [
        "lux", "luxury", "premium", "quiet", "boutique", "highend", "high-end", "handmade",
        "classic", "elegant", "formal-lux"
    ],
    "boots": [
        "boot", "boots", "chelsea", "combat", "ankleboot", "ankle-boot", "chukka"
    ],
    "sandals": [
        "sandal", "sandals", "dep", "d√©p", "slide", "slides", "slipper", "flipflop", "flip-flop"
    ],
    "runner": [
        "runner", "running", "run", "jog", "training", "sport", "the thao", "the-thao", "gym"
    ],
    "sneaker": [
        "sneaker", "sneakers", "tennis", "casual-sneaker", "street", "streetwear"
    ],
    "casual": [
        "casual", "daily", "everyday", "basic", "lifestyle"
    ],
}

def smart_detect_shoe_type(filename: str):
    """
    Tr·∫£ v·ªÅ: (shoe_type, confidence(0-100), reason)
    """
    n = normalize_filename(filename)
    if not n:
        return "sneaker", 30, "Kh√¥ng c√≥ t√™n file ƒë·ªÉ suy lu·∫≠n"

    scores = {k: 0 for k in SHOE_TYPES}
    hits = {k: [] for k in SHOE_TYPES}

    # ∆∞u ti√™n m·∫°nh cho leather/luxury khi c√≥ keyword r√µ
    for stype, kws in KEYWORD_RULES.items():
        for kw in kws:
            # match theo word-boundary m·ªÅm (c√≥ th·ªÉ c√≥ d·∫•u g·∫°ch)
            if kw in n:
                w = 8
                if stype in ["leather", "luxury"]:
                    w = 12
                if stype in ["boots", "sandals"]:
                    w = 10
                scores[stype] += w
                hits[stype].append(kw)

    # Heuristic n√¢ng c·∫•p: n·∫øu c√≥ "da" ho·∫∑c "cong so" -> leather
    if re.search(r"\bda\b", n) or "giay da" in n or "cong so" in n or "c√¥ng s·ªü" in n:
        scores["leather"] += 10
        hits["leather"].append("da/cong-so")

    # N·∫øu leather m·∫°nh th√¨ gi·∫£m kh·∫£ nƒÉng sneaker/runner
    if scores["leather"] >= 12:
        scores["sneaker"] = max(0, scores["sneaker"] - 6)
        scores["runner"] = max(0, scores["runner"] - 6)

    # Quy t·∫Øc ∆∞u ti√™n: n·∫øu leather v√† luxury ƒë·ªÅu c√≥ ƒëi·ªÉm, ∆∞u ti√™n luxury khi luxury >= leather
    # (v√¨ nhi·ªÅu file ƒë·∫∑t t√™n premium/quiet luxury cho gi√†y da)
    best = max(scores.items(), key=lambda x: x[1])[0]
    best_score = scores[best]

    # N·∫øu kh√¥ng c√≥ keyword g√¨ -> m·∫∑c ƒë·ªãnh sneaker nh∆∞ng confidence th·∫•p
    if best_score <= 0:
        return "sneaker", 25, "Kh√¥ng c√≥ keyword nh·∫≠n d·∫°ng (fallback sneaker)"

    # confidence
    # max theoretical ~ 40-60; ta clamp v·ªÅ 40..95
    conf = min(95, max(40, int(best_score * 4)))
    reason = f"Match: {', '.join(hits[best][:6])}" if hits[best] else "Heuristic score"
    return best, conf, reason

# =========================
# THO·∫†I: √©p ra ƒê√öNG 3 c√¢u, kh√¥ng na n√° nhau
# =========================
TONE_LINE_BANK = {
    "T·ª± tin": [
        "M√¨nh th√≠ch c·∫£m gi√°c g·ªçn g√†ng, b∆∞·ªõc ƒëi nh√¨n c≈©ng r√µ r√†ng h∆°n.",
        "Form l√™n ch√¢n ·ªïn, ph·ªëi ƒë·ªì c≈©ng d·ªÖ m√† kh√¥ng c·∫ßn c·∫ßu k·ª≥.",
        "ƒêi c·∫£ ng√†y v·∫´n th·∫•y nh·ªãp ch√¢n kh√° tho·∫£i m√°i.",
        "Nh√¨n t·ªïng th·ªÉ s·∫°ch s·∫Ω, h·ª£p ki·ªÉu m·∫∑c ƒë∆°n gi·∫£n.",
        "M√¨nh ch·ªçn ƒë√¥i n√†y khi mu·ªën m·ªçi th·ª© g·ªçn v√† ch·∫Øc.",
        "C·∫£m gi√°c di chuy·ªÉn m∆∞·ª£t, kh√¥ng b·ªã v∆∞·ªõng nh·ªãp.",
        "ƒê·ª©ng d√°ng l√™n nh√¨n t·ª± tin h∆°n h·∫≥n."
    ],
    "Truy·ªÅn c·∫£m": [
        "C√≥ nh·ªØng ƒë√¥i mang v√†o l√† mood t·ª± nhi√™n d·ªãu l·∫°i.",
        "Nh√¨n k·ªπ m·ªõi th·∫•y c√°i hay n·∫±m ·ªü s·ª± tinh gi·∫£n.",
        "M√¨nh th√≠ch c·∫£m gi√°c v·ª´a v·∫∑n, nh·∫π nh√†ng khi di chuy·ªÉn.",
        "Kh√¥ng c·∫ßn n·ªïi b·∫≠t qu√°, nh∆∞ng c√†ng nh√¨n c√†ng c√≥ gu.",
        "√Ånh s√°ng l√™n form nh√¨n r·∫•t √™m v√† m·ªÅm m·∫Øt.",
        "ƒêi ch·∫≠m th√¥i m√† th·∫•y m·ªçi th·ª© c√¢n b·∫±ng h∆°n."
    ],
    "M·∫°nh m·∫Ω": [
        "M√¨nh c·∫ßn s·ª± ch·∫Øc ch√¢n ƒë·ªÉ gi·ªØ nh·ªãp c·∫£ ng√†y.",
        "B∆∞·ªõc nhanh h∆°n m·ªôt ch√∫t v·∫´n th·∫•y ·ªïn ƒë·ªãnh.",
        "Nh·ªãp ƒëi d·ª©t kho√°t, c·∫£m gi√°c g·ªçn v√† v·ªØng.",
        "Ng√†y b·∫≠n r·ªôn th√¨ m√¨nh ∆∞u ti√™n ki·ªÉu ch·∫Øc ch·∫Øn nh∆∞ v·∫≠y.",
        "Di chuy·ªÉn li√™n t·ª•c m√† v·∫´n gi·ªØ ƒë∆∞·ª£c phong th√°i.",
        "C·∫£m gi√°c b√°m nh·ªãp t·ªët, kh√¥ng b·ªã ch√¥ng ch√™nh."
    ],
    "L√£ng m·∫°n": [
        "Chi·ªÅu xu·ªëng l√† m√¨nh th√≠ch ƒëi ch·∫≠m ƒë·ªÉ c·∫£m nh·∫≠n kh√¥ng kh√≠.",
        "Nh·ªãp b∆∞·ªõc th∆∞ th·∫£ l√†m m·ªçi th·ª© nh·∫π h∆°n.",
        "C√≥ c·∫£m gi√°c tinh t·∫ø r·∫•t v·ª´a ƒë·ªß, kh√¥ng ph√¥ tr∆∞∆°ng.",
        "Kh√¥ng gian y√™n y√™n l√† t·ª± nhi√™n th·∫•y d·ªÖ ch·ªãu.",
        "M√¨nh th√≠ch ki·ªÉu ƒë∆°n gi·∫£n m√† v·∫´n c√≥ c·∫£m x√∫c.",
        "ƒêi v√†i b∆∞·ªõc th√¥i m√† mood ƒë√£ kh√°c."
    ],
    "T·ª± nhi√™n": [
        "M√¨nh ∆∞u ti√™n s·ª± tho·∫£i m√°i, mang l√† mu·ªën ƒëi ti·∫øp.",
        "C·∫£m gi√°c nh·∫π nh√†ng, h·ª£p nh·ªØng ng√†y mu·ªën th·∫£ l·ªèng.",
        "Nh√¨n t·ªïng th·ªÉ t·ª± nhi√™n, kh√¥ng b·ªã g√≤ b√≥.",
        "ƒêi l√¢u m·ªôt ch√∫t v·∫´n th·∫•y d·ªÖ ch·ªãu.",
        "Chuy·ªÉn ƒë·ªông nh·∫π, nh·ªãp ch√¢n √™m v√† ƒë·ªÅu.",
        "M√¨nh th√≠ch ki·ªÉu ƒë∆°n gi·∫£n, g·∫ßn g≈©i."
    ],
}

def split_sentences(text: str):
    # t√°ch c√¢u theo . ! ? (gi·ªØ s·∫°ch)
    t = re.sub(r"\s+", " ", (text or "").strip())
    if not t:
        return []
    parts = re.split(r"(?<=[\.\!\?])\s+", t)
    parts = [p.strip() for p in parts if p.strip()]
    # n·∫øu ng∆∞·ªùi d√πng vi·∫øt kh√¥ng c√≥ d·∫•u ch·∫•m -> coi nh∆∞ 1 c√¢u
    return parts

def pick_unique_voice_line(pool, used_set):
    candidates = [x for x in pool if x not in used_set]
    if not candidates:
        used_set.clear()
        candidates = pool[:]
    line = random.choice(candidates)
    used_set.add(line)
    return line

def get_dialogue_text(row, tone):
    """
    ƒê·∫£m b·∫£o output: ƒê√öNG 3 c√¢u, kh√¥ng l·∫∑p √Ω ki·ªÉu ƒë·∫£o l·∫°i.
    - ∆∞u ti√™n l·∫•y t·ª´ CSV (c·ªôt dialogue/text/...)
    - n·∫øu CSV ch·ªâ c√≥ 1 c√¢u -> b·ªï sung 2 c√¢u t·ª´ bank theo tone (unique)
    - n·∫øu CSV c√≥ 2 c√¢u -> b·ªï sung 1 c√¢u t·ª´ bank
    - n·∫øu CSV c√≥ >=3 c√¢u -> l·∫•y 3 c√¢u ƒë·∫ßu ti√™n kh√°c nhau (random)
    """
    csv_text = ""
    for col in ["dialogue", "text", "line", "content", "script", "noi_dung"]:
        if col in row:
            t = safe_text(row.get(col))
            if t:
                csv_text = t
                break

    bank = TONE_LINE_BANK.get(tone, TONE_LINE_BANK["T·ª± tin"])

    # n·∫øu CSV c√≥ text
    if csv_text:
        sents = split_sentences(csv_text)
        # n·∫øu CSV kh√¥ng c√≥ d·∫•u c√¢u (1 c√¢u d√†i) -> coi l√† 1
        if len(sents) == 0:
            sents = [csv_text.strip()]

        # l√†m s·∫°ch tr√πng
        uniq = []
        for s in sents:
            ss = s.strip()
            if ss and ss not in uniq:
                uniq.append(ss)

        if len(uniq) >= 3:
            # ch·ªçn 3 c√¢u kh√°c nhau, random ƒë·ªÉ kh√¥ng ‚Äúna n√°‚Äù
            chosen = random.sample(uniq, 3)
            return " ".join([c if c.endswith((".", "!", "?")) else c + "." for c in chosen])

        if len(uniq) == 2:
            extra = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
            chosen = [uniq[0], uniq[1], extra]
            return " ".join([c if c.endswith((".", "!", "?")) else c + "." for c in chosen])

        if len(uniq) == 1:
            extra1 = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
            extra2 = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
            chosen = [uniq[0], extra1, extra2]
            return " ".join([c if c.endswith((".", "!", "?")) else c + "." for c in chosen])

    # fallback: kh√¥ng c√≥ csv_text
    extra1 = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
    extra2 = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
    extra3 = pick_unique_voice_line(bank, st.session_state.used_voice_lines)
    chosen = [extra1, extra2, extra3]
    return " ".join([c if c.endswith((".", "!", "?")) else c + "." for c in chosen])

def scene_line(scene):
    return (
        f"{scene.get('lighting','')} ‚Ä¢ {scene.get('location','')} ‚Ä¢ "
        f"{scene.get('motion','')} ‚Ä¢ {scene.get('weather','')} ‚Ä¢ mood {scene.get('mood','')}"
    ).strip(" ‚Ä¢")

def filter_scenes_by_shoe_type(shoe_type):
    f = [s for s in scenes if safe_text(s.get("shoe_type")).lower() == shoe_type.lower()]
    return f if f else scenes

def filter_dialogues(shoe_type, tone):
    tone_f = [d for d in dialogues if safe_text(d.get("tone")) == tone]
    if not tone_f:
        tone_f = dialogues
    shoe_f = [d for d in tone_f if safe_text(d.get("shoe_type")).lower() == shoe_type.lower()]
    return shoe_f if shoe_f else tone_f

# =========================
# BUILD PROMPTS (FIX: include shoe_name + shoe_type)
# =========================
def build_prompt_p1(shoe_name, shoe_type, tone):
    s_pool = filter_scenes_by_shoe_type(shoe_type)
    d_pool = filter_dialogues(shoe_type, tone)

    s = pick_unique(s_pool, st.session_state.used_scene_ids, "id")
    d = pick_unique(d_pool, st.session_state.used_dialogue_ids, "id")
    disclaimer = random.choice(disclaimers_p1 if disclaimers_p1 else DISCLAIMER_P1_FALLBACK)

    dialogue_text = get_dialogue_text(d, tone)

    return f"""
SORA VIDEO PROMPT ‚Äî PROMPT 1 (KH√îNG CAMEO) ‚Äî TIMELINE LOCK 10s
VOICE ID: {CAMEO_VOICE_ID}

VIDEO SETUP
- Video d·ªçc 9:16 ‚Äî 10s ‚Äî Ultra Sharp 4K
- Video th·∫≠t, chuy·ªÉn ƒë·ªông m∆∞·ª£t (kh√¥ng ·∫£nh tƒ©nh)
- KH√îNG ng∆∞·ªùi ‚Ä¢ KH√îNG cameo ‚Ä¢ KH√îNG xu·∫•t hi·ªán nh√¢n v·∫≠t
- NO text ‚Ä¢ NO logo ‚Ä¢ NO watermark
- NO blur ‚Ä¢ NO haze ‚Ä¢ NO glow

SHOE REFERENCE ‚Äî ABSOLUTE LOCK
- Use ONLY the uploaded shoe image as reference.
- KEEP 100% shoe identity (shape, sole, panels, stitching, proportions).
- NO redesign ‚Ä¢ NO deformation ‚Ä¢ NO guessing ‚Ä¢ NO color shift

PRODUCT (for consistency, not for selling)
- shoe_name: {shoe_name}
- shoe_type: {shoe_type}

SCENE
- {scene_line(s)}

AUDIO TIMELINE
0.0‚Äì1.2s: Kh√¥ng tho·∫°i, ambient + nh·∫°c n·ªÅn r·∫•t nh·∫π
1.2‚Äì6.9s: VOICE ON (ƒê√öNG 3 c√¢u, ƒë·ªùi th∆∞·ªùng, chia s·∫ª tr·∫£i nghi·ªám)
6.9‚Äì10.0s: VOICE OFF (im h·∫≥n) + fade-out 9.2‚Äì10.0s

[VOICEOVER {CAMEO_VOICE_ID} | 1.2‚Äì6.9s]
{dialogue_text}

SAFETY / MI·ªÑN TR·ª™
- {disclaimer}
""".strip()

def build_prompt_p2(shoe_name, shoe_type, tone):
    s_pool = filter_scenes_by_shoe_type(shoe_type)
    d_pool = filter_dialogues(shoe_type, tone)

    s = pick_unique(s_pool, st.session_state.used_scene_ids, "id")
    d = pick_unique(d_pool, st.session_state.used_dialogue_ids, "id")
    disclaimer = random.choice(disclaimers_p2) if disclaimers_p2 else "Th√¥ng tin chi ti·∫øt vui l√≤ng xem trong gi·ªè h√†ng."

    dialogue_text = get_dialogue_text(d, tone)

    return f"""
SORA VIDEO PROMPT ‚Äî PROMPT 2 (C√ì CAMEO) ‚Äî TIMELINE LOCK 10s
CAMEO VOICE ID: {CAMEO_VOICE_ID}

VIDEO SETUP
- Video d·ªçc 9:16 ‚Äî 10s ‚Äî Ultra Sharp 4K
- Video th·∫≠t, chuy·ªÉn ƒë·ªông m∆∞·ª£t (kh√¥ng ·∫£nh tƒ©nh)
- NO text ‚Ä¢ NO logo ‚Ä¢ NO watermark
- NO blur ‚Ä¢ NO haze ‚Ä¢ NO glow

CAMEO SETUP (SAFE)
- Cameo xu·∫•t hi·ªán t·ª± nhi√™n, kh√¥ng CTA, kh√¥ng b√°n h√†ng
- Voice n√≥i ki·ªÉu chia s·∫ª tr·∫£i nghi·ªám ƒë·ªùi th∆∞·ªùng

SHOE REFERENCE ‚Äî ABSOLUTE LOCK
- Use ONLY the uploaded shoe image as reference.
- KEEP 100% shoe identity (shape, sole, panels, stitching, proportions).
- NO redesign ‚Ä¢ NO deformation ‚Ä¢ NO guessing ‚Ä¢ NO color shift

PRODUCT (for consistency, not for selling)
- shoe_name: {shoe_name}
- shoe_type: {shoe_type}

SCENE
- {scene_line(s)}

AUDIO TIMELINE
0.0‚Äì1.0s: Kh√¥ng tho·∫°i, ambient + nh·∫°c n·ªÅn r·∫•t nh·∫π
1.0‚Äì6.9s: VOICE ON (ƒê√öNG 3 c√¢u, ƒë·ªùi th∆∞·ªùng, chia s·∫ª tr·∫£i nghi·ªám)
6.9‚Äì10.0s: VOICE OFF (im h·∫≥n) + fade-out 9.2‚Äì10.0s

[VOICEOVER {CAMEO_VOICE_ID} | 1.0‚Äì6.9s]
{dialogue_text}

SAFETY / MI·ªÑN TR·ª™ (PROMPT 2)
- {disclaimer}
""".strip()

# =========================
# UI (G·ªåN)
# =========================
left, right = st.columns([1, 1])

with left:
    uploaded = st.file_uploader("üì§ T·∫£i ·∫£nh gi√†y", type=["jpg", "png", "jpeg"])
    mode = st.radio("Ch·ªçn lo·∫°i prompt", ["PROMPT 1 ‚Äì Kh√¥ng cameo", "PROMPT 2 ‚Äì C√≥ cameo"], index=1)
    tone = st.selectbox("Ch·ªçn tone tho·∫°i", ["Truy·ªÅn c·∫£m", "T·ª± tin", "M·∫°nh m·∫Ω", "L√£ng m·∫°n", "T·ª± nhi√™n"], index=1)
    count = st.slider("S·ªë l∆∞·ª£ng prompt", 1, 10, 5)

with right:
    st.subheader("üìå H∆∞·ªõng d·∫´n nhanh")
    st.write("1) Upload ·∫£nh ‚Ä¢ 2) Ch·ªçn Prompt 1/2 ‚Ä¢ 3) Ch·ªçn tone ‚Ä¢ 4) B·∫•m SINH ‚Ä¢ 5) B·∫•m s·ªë 1..N ƒë·ªÉ xem & COPY")
    st.caption(f"Dialogues columns: {dialogue_cols}")
    st.caption(f"Scenes columns: {scene_cols}")
    if Path("disclaimer_prompt1.csv").exists():
        st.success("‚úÖ ƒê√£ c√≥ disclaimer_prompt1.csv (Prompt 1 s·∫Ω random theo file).")
    else:
        st.info("‚ÑπÔ∏è Ch∆∞a c√≥ disclaimer_prompt1.csv (Prompt 1 d√πng danh s√°ch d·ª± ph√≤ng).")

st.divider()

if uploaded:
    # shoe_name l·∫•y t·ª´ filename (kh√¥ng ph·ª• thu·ªôc shoe_type)
    shoe_name = extract_shoe_name(uploaded.name)

    # Smart auto detect shoe_type
    auto_type, auto_conf, auto_reason = smart_detect_shoe_type(uploaded.name)

    st.info(f"üßæ **shoe_name (l·∫•y t·ª´ t√™n file):** `{shoe_name}`")

    shoe_type_choice = st.selectbox(
        "Ch·ªçn shoe_type (Auto ho·∫∑c ch·ªçn tay)",
        ["Auto"] + SHOE_TYPES,
        index=0
    )
    shoe_type = auto_type if shoe_type_choice == "Auto" else shoe_type_choice

    if shoe_type_choice == "Auto":
        # C·∫£nh b√°o khi confidence th·∫•p
        if auto_conf < 60:
            st.warning(
                f"‚ö†Ô∏è Auto ƒëo√°n **{auto_type}** nh∆∞ng ƒë·ªô tin c·∫≠y th·∫•p (**{auto_conf}%**). "
                f"L√Ω do: {auto_reason}. Khuy√™n ch·ªìng ch·ªçn tay cho ch·∫Øc."
            )
        else:
            st.success(f"‚úÖ Auto ƒëo√°n shoe_type: **{auto_type}** ({auto_conf}%) ‚Ä¢ {auto_reason}")
    else:
        # N·∫øu user ch·ªçn tay kh√°c auto th√¨ b√°o
        if shoe_type_choice != auto_type and auto_conf >= 60:
            st.warning(f"‚ÑπÔ∏è Ch·ªìng ch·ªçn tay **{shoe_type_choice}** kh√°c Auto (**{auto_type}**). OK, app s·∫Ω d√πng ch·ªçn tay.")
        st.success(f"üëü shoe_type (ch·ªçn tay): **{shoe_type_choice}**")

    btn_label = "üé¨ SINH PROMPT 1" if mode.startswith("PROMPT 1") else "üé¨ SINH PROMPT 2"
    if st.button(btn_label, use_container_width=True):
        arr = []
        # reset used_voice_lines m·ªói l·∫ßn sinh batch ƒë·ªÉ 1 batch kh√¥ng tr√πng c√¢u qu√° nhi·ªÅu
        st.session_state.used_voice_lines.clear()

        for _ in range(count):
            p = build_prompt_p1(shoe_name, shoe_type, tone) if mode.startswith("PROMPT 1") else build_prompt_p2(shoe_name, shoe_type, tone)
            arr.append(p)
        st.session_state.generated_prompts = arr

    prompts = st.session_state.get("generated_prompts", [])
    if prompts:
        st.markdown("### ‚úÖ Ch·ªçn prompt (b·∫•m s·ªë)")
        tabs = st.tabs([f"{i+1}" for i in range(len(prompts))])
        for i, tab in enumerate(tabs):
            with tab:
                st.text_area("Prompt", prompts[i], height=420, key=f"view_{i}")
                copy_button(prompts[i], key=f"copy_view_{i}")

else:
    st.warning("‚¨ÜÔ∏è Upload ·∫£nh gi√†y ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

st.divider()
if st.button("‚ôªÔ∏è Reset ch·ªëng tr√πng"):
    st.session_state.used_dialogue_ids.clear()
    st.session_state.used_scene_ids.clear()
    st.session_state.used_voice_lines.clear()
    st.session_state.generated_prompts = []
    st.success("‚úÖ ƒê√£ reset")
